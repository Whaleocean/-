
* 网络爬虫的本质就是一种递归方式。为了找到 URL 链接，它们必须首先获取网页内容，检查这个页面的内容，再寻找另一个URL，然后获取 URL对应的网页内容，不断循环这一过程。
* 考虑需要消耗多少网络流量，还要尽力思考能不能让采集目标的服务器负载更低一些。
